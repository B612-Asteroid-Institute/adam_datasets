{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e595e5cd",
   "metadata": {},
   "source": [
    "## SkyMapper Data Release 2 (DR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dcba76",
   "metadata": {},
   "source": [
    "Sherry Yang - 2022-11-30\n",
    "\n",
    "Information on the columns each of tables contains can be found here:\\\n",
    "[Browse Table Metadata | DR2](https://skymapper.anu.edu.au/table-browser/dr2)\\\n",
    "**References**:\\\n",
    " https://dx.doi.org/10.25914/5ce60d31ce759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f38b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvo as vo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from astropy.time import Time\n",
    "from astropy import units as u\n",
    "from tqdm import tqdm, trange\n",
    "from math import ceil\n",
    "from astropy.time import TimeDelta\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def querySkymapper(start, end, newStart):\n",
    "    \n",
    "    tap_service = vo.dal.TAPService(\"https://api.skymapper.nci.org.au/public/tap/\")\n",
    "    \n",
    "    #Find the range of expourse_id in this date\n",
    "    regionQuery = f\"\"\"\n",
    "    SELECT COUNT(image_id) AS num, MAX(image_id) AS max_id,MIN(image_id) AS min_id FROM dr2.images WHERE \"date\" >= {start} AND \"date\" < {end}\n",
    "    \"\"\"\n",
    "    region = tap_service.search(regionQuery)\n",
    "    region = pd.DataFrame(region) \n",
    "    \n",
    "    #tarnsform date format here for file name\n",
    "    date = Time(start, format='mjd')\n",
    "    date = date.to_value('iso',subfmt='date')\n",
    "    \n",
    "    if(region['num'][0] == 0):\n",
    "        return None\n",
    "    \n",
    "    #Defined the range of expourse_id\n",
    "    minID = region['min_id'][0]\n",
    "    maxID = region['max_id'][0]\n",
    "    if(newStart > minID):\n",
    "        minID = newStart\n",
    "        \n",
    "    #The main qurey\n",
    "    query = f\"\"\"SELECT \n",
    "    a.object_id as obj_id,\n",
    "    b.image_id as exposure_id,\n",
    "    b.ccd as ccd,\n",
    "    c.\"date\" as mjd_utc,\n",
    "    b.ra_img as ra,\n",
    "    b.decl_img as dec,\n",
    "    a.e_raj2000 as ra_sigma,\n",
    "    a.e_dej2000 as dec_sigma,\n",
    "    b.filter as filter,\n",
    "    b.mag_psf as mag,\n",
    "    b.e_mag_psf as mag_sigma,\n",
    "    'Q55'as obscode,\n",
    "    c.exp_time as exposure_time\n",
    "\n",
    "    FROM\n",
    "    (Select image_id, \"date\", exp_time, filter, object from dr2.images) as c \n",
    "    INNER JOIN \n",
    "    (select object_id, ccd, class_star,image_id,filter,ra_img,decl_img, mag_psf, e_mag_psf from dr2.photometry)as b\n",
    "    ON b.image_id = c.image_id\n",
    "    INNER JOIN \n",
    "    (select object_id, raj2000,dej2000,e_raj2000,e_dej2000, ngood from dr2.master) as a\n",
    "    on a.object_id = b.object_id\n",
    "    \n",
    "    WHERE c.image_id >= {minID}\n",
    "    AND  c.image_id <= {maxID}\"\"\"\n",
    "    \n",
    "    \n",
    "    tap_results = tap_service.search(query, timeout = 600)\n",
    "    \n",
    "    if(len(tap_results)==0):\n",
    "        return None\n",
    "    \n",
    "    # A constant convert second to Mjd\n",
    "    dt2 = TimeDelta(1, format='sec')\n",
    "    to_mjd = dt2.to_value('jd')   \n",
    "    \n",
    "    df = pd.DataFrame(tap_results) \n",
    "    \n",
    "    #If reach the Skymapper maximum query limit, the last exposure_id data is incomplete, drop it. \n",
    "    newStart = start;\n",
    "    over = (df.shape[0] == 1000000)\n",
    "    if(over):\n",
    "        newStart = df.exposure_id[1000000- 1]\n",
    "        df = df[df['exposure_id'] < newStart] \n",
    "    \n",
    "    #Format transformation\n",
    "    exposure_id = df[\"exposure_id\"].values\n",
    "    ccd = df[\"ccd\"].values\n",
    "    object_id = df[\"obj_id\"].values\n",
    "    obs_id = [f\"{o}{c}{e}\" for o,c, e in zip(object_id, ccd,exposure_id)] #make a unique id for each observation of each object\n",
    "    df[\"obs_id\"] = obs_id\n",
    "    df['obscode'] = \"Q55\"\n",
    "    df['dec_sigma'] = df['dec_sigma']*u.mas.to(u.deg)\n",
    "    df['ra_sigma'] = df['ra_sigma']*u.mas.to(u.deg)\n",
    "    df['mjd_utc'] = df['exposure_time']*to_mjd/2 +df['mjd_utc'] #change data to mid point\n",
    "    df = df.rename(columns={\"obscode\":\"observatory_code\"})\n",
    "    df = df.astype({\"exposure_id\": str}, errors='raise') \n",
    "    df = df.astype({\"observatory_code\": str}, errors='raise') \n",
    "    df = df.astype({\"obs_id\": str}, errors='raise') \n",
    "    \n",
    "    df = df.drop(columns=['exposure_time'])\n",
    "    df = df.drop(columns=['ccd'])\n",
    "    \n",
    "    #Output \n",
    "    DATA_DIR = \"/epyc/projects/adam_datasets/skyMapper_dr2/data\"\n",
    "    file_name = os.path.join(DATA_DIR, f\"dr2_observations_{date}.h5\")\n",
    "    df.to_hdf(path_or_buf= file_name,index=False,append=True,key='data',format = 'table',min_itemsize={ 'obs_id' : 30 })\n",
    "    \n",
    "    #If reach the row maximum of skyMapper qurey, do recursion\n",
    "    if (over):\n",
    "        querySkymapper(start, end, newStart)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f433fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupQuery(start, end):\n",
    "    for i in range(start,end): \n",
    "        querySkymapper(i, i+1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "\n",
    "for i in range(20):\n",
    "\tprocess = multiprocessing.Process(target=groupQuery, args=(56764 + i *100,56764+ i*100+100))\n",
    "\tjobs.append(process)\n",
    "\n",
    "for j in jobs: \n",
    "\tj.start()\n",
    "\n",
    "for j in jobs:\n",
    "\tj.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25081ba1",
   "metadata": {},
   "source": [
    "### Handle Object_id is NULL in dr2.photometry\n",
    "There some Observations don't have a object_id, and there no attributes to distinct those NULL objects in the same exposure_id and same ccd, so here by make a query for all NULL objects, and indexs them by a index number + ccd + exposureid. Also clear up duplicate index which caused by recursion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3220c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_null(start,end):\n",
    "    for index in range(start,end):\n",
    "        date = Time(index, format='mjd') #Timeobject\n",
    "        date = date.to_value('iso',subfmt='date') #String formate 2014-03-20\n",
    "        DATA_DIR = \"/epyc/projects/adam_datasets/skyMapper_dr2/data_test\"\n",
    "        file_name = os.path.join(DATA_DIR, f\"dr2_observations_{date}.h5\")\n",
    "        if(not os.path.isfile(file_name)):\n",
    "            continue\n",
    "\n",
    "        store = pd.read_hdf(file_name, \"data\",mode = 'r')\n",
    "        store = store.reset_index(drop=True)\n",
    "        nullobject = store.loc[store['obj_id'] == 0]\n",
    "        store.loc[store['obj_id'] == 0,'obs_id'] =  [f\"{i}#{o}\" for i,o in zip(nullobject.index, store['obs_id'])]\n",
    "        \n",
    "        file = open(\"final_stat.txt\", \"a\")  # write mode\n",
    "        file.write(f\"{date},{store.shape[0]},{nullobject.shape[0]}\\n\")\n",
    "        file.close()\n",
    "        \n",
    "        DATA_DIR = \"/epyc/projects/adam_datasets/skyMapper_dr2/data\"\n",
    "        file_name = os.path.join(DATA_DIR, f\"dr2_observations_{date}.h5\")\n",
    "        store.to_hdf(path_or_buf= file_name,index=False,append=True,key='data',format = 'table',min_itemsize={ 'obs_id' : 35 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31562055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#56730,58192\n",
    "jobs = []\n",
    "Slice = ceil ((58192-56730) / 20)\n",
    "for i in range(20):\n",
    "\tprocess = multiprocessing.Process(target=index_null, args=(56730+Slice * i, 56730+Slice * (i+1)))\n",
    "\tjobs.append(process)\n",
    "\n",
    "for j in jobs: \n",
    "\tj.start()\n",
    "\n",
    "for j in jobs:\n",
    "\tj.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabaaa0b",
   "metadata": {},
   "source": [
    "### Indexing Code:\n",
    "python index_observations.py data dataset SKYMAPPER_DR2 --nside 32 --dataset_name \"SkyMapper Southern Sky Survey (DR2)\" --reference_doi https://doi.org/10.25914/5ce60d31ce759 --documentation_url https://skymapper.anu.edu.au/data-release/dr2/ --sia_url https://api.skymapper.nci.org.au/public/siap/dr2/query?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Precovery (Python 3.9)",
   "language": "python",
   "name": "precovery_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
